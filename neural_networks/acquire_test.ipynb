{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78f2bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Tate Smith - u@ou.edu\n",
    "Date: Feb. 2, 2022\n",
    "\n",
    "Adapted from the following:\n",
    "\n",
    "Deep Learning Demo: XOR\n",
    "\n",
    "Command line version\n",
    "\n",
    "Andrew H. Fagg (andrewhfagg@gmail.com)\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "# Tensorflow 2.x way of doing things\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#################################################################\n",
    "# Default plotting parameters\n",
    "FONTSIZE = 18\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = FONTSIZE\n",
    "\n",
    "#################################################################\n",
    "def build_model(n_inputs, n_hidden, n_output, activation='elu', lrate=0.001):\n",
    "    '''\n",
    "    Construct a network with one hidden layer\n",
    "    - Adam optimizer\n",
    "    - MSE loss\n",
    "    \n",
    "    :param n_inputs: Number of input dimensions\n",
    "    :param n_hidden: Number of units in the hidden layer\n",
    "    :param n_output: Number of ouptut dimensions\n",
    "    :param activation: Activation function to be used for hidden and output units\n",
    "    :param lrate: Learning rate for Adam Optimizer\n",
    "    '''\n",
    "    model = Sequential();\n",
    "    model.add(InputLayer(input_shape=(n_inputs,)))\n",
    "    model.add(Dense(n_hidden, use_bias=True, name=\"hidden\", activation=activation))\n",
    "    model.add(Dense(n_hidden, use_bias=True, name=\"hidden1\", activation=activation))\n",
    "    model.add(Dense(n_hidden, use_bias=True, name=\"hidden2\", activation=activation))\n",
    "    model.add(Dense(n_hidden, use_bias=True, name=\"hidden3\", activation=activation))\n",
    "    model.add(Dense(n_output, use_bias=True, name=\"output\", activation=activation))\n",
    "    \n",
    "    # Optimizer\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lrate, beta_1=0.9, beta_2=0.999,\n",
    "                                epsilon=None, decay=0.0, amsgrad=False)\n",
    "    \n",
    "    # Bind the optimizer and the loss function to the model\n",
    "    model.compile(loss='mse', optimizer=opt)\n",
    "    \n",
    "    # Generate an ASCII representation of the architecture\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "def args2string(args):\n",
    "    '''\n",
    "    Translate the current set of arguments\n",
    "    \n",
    "    :param args: Command line arguments\n",
    "    '''\n",
    "    return \"exp_%02d_hidden_%02d\"%(args.exp, args.hidden)\n",
    "    \n",
    "    \n",
    "########################################################\n",
    "def execute_exp(args):\n",
    "    '''\n",
    "    Execute a single instance of an experiment.  The details are specified in the args object\n",
    "    \n",
    "    :param args: Command line arguments\n",
    "    '''\n",
    "\n",
    "    ##############################\n",
    "    \n",
    "    # Load in Homework0 data:\n",
    "    fp = open(\"hw0_dataset.pkl\", \"rb\")\n",
    "    data = pickle.load(fp)\n",
    "    fp.close()\n",
    "    \n",
    "    model = build_model(data[\"ins\"].shape[1], args.hidden, data[\"outs\"].shape[1], activation='tanh')\n",
    "\n",
    "    # Callbacks\n",
    "    \n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=1000,\n",
    "                                                      restore_best_weights=True,\n",
    "                                                      min_delta=0.00001)\n",
    "\n",
    "    # Describe arguments\n",
    "    argstring = args2string(args)\n",
    "    print(\"EXPERIMENT: %s\"%argstring)\n",
    "    \n",
    "    # Only execute if we are 'going'\n",
    "    if not args.nogo:\n",
    "        # Training\n",
    "        print(\"Training...\")\n",
    "        \n",
    "        # Note: faking validation data set\n",
    "        history = model.fit(x=data[\"ins\"], y=data[\"outs\"], epochs=args.epochs, \n",
    "                            verbose=False,\n",
    "                            validation_data=(data[\"ins\"], data[\"outs\"]),\n",
    "                            callbacks=[early_stopping_cb])\n",
    "        \n",
    "        print(\"Done Training\")\n",
    "        abs_error = np.abs(model.predict(data[\"ins\"]) - data[\"outs\"])\n",
    "        \n",
    "        # Save the training history\n",
    "        fp = open(\"results/hw0_results_%s.pkl\"%(argstring), \"wb\")\n",
    "        pickle.dump(history.history, fp)\n",
    "        pickle.dump(args, fp)\n",
    "        pickle.dump(abs_error, fp)\n",
    "        fp.close()\n",
    "\n",
    "\n",
    "def display_learning_curve(fname):\n",
    "    '''\n",
    "    Display the learning curve that is stored in fname\n",
    "    \n",
    "    :param fname: Results file to load and dipslay\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Load the history file and display it\n",
    "    fp = open(fname, \"rb\")\n",
    "    history = pickle.load(fp)\n",
    "    # TODO\n",
    "    fp.close()\n",
    "    \n",
    "    # Display\n",
    "    plt.plot(history['loss'])\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('epochs')\n",
    "\n",
    "def display_learning_curve_set(dir, base):\n",
    "    '''\n",
    "    Plot the learning curves for a set of results\n",
    "    \n",
    "    :param base: Directory containing a set of results files\n",
    "    '''\n",
    "    # Find the list of files in the local directory that match base_[\\d]+.pkl\n",
    "    files = [f for f in os.listdir(dir) if re.match(r'%s.+.pkl'%(base), f)]\n",
    "    files.sort()\n",
    "    \n",
    "    for f in files:\n",
    "        with open(\"%s/%s\"%(dir,f), \"rb\") as fp:\n",
    "            history = pickle.load(fp)\n",
    "            plt.plot(history['loss'])\n",
    "            \n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(files, fontsize=6)\n",
    "    plt.savefig('resultSet.png')\n",
    "    \n",
    "def display_error_hist(dir, base):\n",
    "    '''\n",
    "    Display a histogram of absolute errors of all model predictions\n",
    "    '''\n",
    "    # Find the list of files in the local directory that match base_[\\d]+.pkl\n",
    "    files = [f for f in os.listdir(dir) if re.match(r'%s.+.pkl'%(base), f)]\n",
    "    files.sort()\n",
    "    errors = []\n",
    "    \n",
    "    for f in files:\n",
    "        with open(\"%s/%s\"%(dir,f), \"rb\") as fp:\n",
    "            hist = pickle.load(fp)\n",
    "            junk = pickle.load(fp)\n",
    "            error = pickle.load(fp)\n",
    "            errors.append(error)\n",
    "            \n",
    "    allErrors = np.concatenate(errors)\n",
    "    plt.close()\n",
    "    plt.hist(allErrors, 300)\n",
    "    plt.savefig('errorHist.png')\n",
    "    \n",
    "    \n",
    "def create_parser():\n",
    "    '''\n",
    "    Create a command line parser for the experiment\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser(description='XOR Learner')\n",
    "    parser.add_argument('--exp', type=int, default=0, help='Experimental index')\n",
    "    parser.add_argument('--epochs', type=int, default=100, help='Number of Training Epochs')\n",
    "    parser.add_argument('--hidden', type=int, default=2, help='Number of hidden units')\n",
    "    parser.add_argument('--gpu', action='store_true', help='Use gpu')\n",
    "    parser.add_argument('--nogo', action='store_true', help='Do not preform the experiment')\n",
    "\n",
    "\n",
    "    return parser\n",
    "\n",
    "'''\n",
    "This next bit of code is executed only if this python file itself is executed\n",
    "(if it is imported into another file, then the code below is not executed)\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    # Parse the command-line arguments\n",
    "    parser = create_parser()\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Turn off GPU?\n",
    "    if not args.gpu:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "        \n",
    "    # GPU check\n",
    "    physical_devices = tf.config.list_physical_devices('GPU') \n",
    "    n_physical_devices = len(physical_devices)\n",
    "    if(n_physical_devices > 0):\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        print('We have %d GPUs\\n'%n_physical_devices)\n",
    "    else:\n",
    "        print('NO GPU')\n",
    "\n",
    "    # Do the work\n",
    "    execute_exp(args)\n",
    "    #display_learning_curve_set('results', 'hw0_results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
